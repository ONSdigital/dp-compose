version: '3.3'
services:
  mongodb:
    image: mongo:3.6
    ports:
      - 27017:27017
    volumes:
      # Load init script to ensure dbs and collections are created
      - ./mongodb/entrypoint-initdb.d/init.js:/docker-entrypoint-initdb.d/init.js:ro
  zookeeper-1:
    image: confluentinc/cp-zookeeper:6.0.0
    expose:
      - 2181
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
  kafka-1:
    image: confluentinc/cp-kafka:6.0.0
    expose:
      - 19092 # exposed port to docker network so that the broker is reachable by other brokers, value needs to match PLAINTEXT port
    ports:
      - 9092:9092 # map localhost port so that broker is reachable from the host, values needs to match PLAINTEXT_HOST port
    depends_on:
      - zookeeper-1
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:19092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 9092 || exit -1"]
      interval: 2s
      timeout: 2s
      retries: 15
  kafka-2:
    image: confluentinc/cp-kafka:6.0.0
    expose:
      - 19092 # exposed port to docker network so that the broker is reachable by other brokers, value needs to match PLAINTEXT port
    ports:
      - 9093:9093 # map localhost port so that broker is reachable from the host, values needs to match PLAINTEXT_HOST port
    depends_on:
      - zookeeper-1
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181
      KAFKA_BROKER_ID: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:19092,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 9093 || exit -1"]
      interval: 2s
      timeout: 2s
      retries: 15

  kafka-3:
    image: confluentinc/cp-kafka:6.0.0
    expose:
      - 19092 # exposed port to docker network so that the broker is reachable by other brokers, value needs to match PLAINTEXT port
    ports:
      - 9094:9094 # map localhost port so that broker is reachable from the host, values needs to match PLAINTEXT_HOST port
    depends_on:
      - zookeeper-1
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181
      KAFKA_BROKER_ID: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:19092,PLAINTEXT_HOST://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 9094 || exit -1"]
      interval: 2s
      timeout: 2s
      retries: 15
  postgres:
    build: ../postgres
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=mysecretpassword
    ports:
      - 5432:5432
  minio:
    image: 'bitnami/minio:latest'
    volumes:
      - ./minio/data:/data
    ports:
      - '9001:9000'
      - '9002:9001'
    environment:
      - MINIO_ROOT_USER=minio-access-key
      - MINIO_ROOT_PASSWORD=minio-secret-key
      - MINIO_DEFAULT_BUCKETS=public-bucket,private-bucket
  vault:
    image: 'hashicorp/vault:latest'
    ports:
      - '8200:8200'
    entrypoint: vault server -dev -dev-kv-v1
    volumes:
      - ./vault/config:/vault/config
    environment:
      - VAULT_DEV_LISTEN_ADDRESS=0.0.0.0:8200
      - VAULT_DEV_ROOT_TOKEN_ID=0000-0000-0000-0000
  kowl:
    image: quay.io/cloudhut/kowl:master
    ports:
      - '9888:8080'
    environment:
      KAFKA_BROKERS: kafka-1:19092,kafka-2:19093,kafka-3:19094
  kouncil:
    image: consdata/kouncil:latest
    ports:
      - '8888:8080'
    environment:
      bootstrapServers:
        kafka-1:19092
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3

  apm:
    image: elastic/apm-server:8.3.2
    cap_add: ["CHOWN", "DAC_OVERRIDE", "SETGID", "SETUID"]
    cap_drop: ["ALL"]
    ports:
    - 8201:8200
    command: >
       apm-server -e
         -E apm-server.rum.enabled=true
         -E setup.kibana.host=kibana:5601
         -E setup.template.settings.index.number_of_replicas=0
         -E apm-server.kibana.enabled=true
         -E apm-server.kibana.host=kibana:5601
         -E apm-server.kibana.username=apm_system
         -E apm-server.kibana.password=IDyz7LreVADvZYcoUQd9
         -E output.elasticsearch.hosts=["elasticsearch:9200"]
         -E output.elasticsearch.username=elastic
         -E output.elasticsearch.password=mY8AKhVUuJHfHythkaFC
         -E output.logstash.enabled=false
    healthcheck:
      interval: 10s
      retries: 12
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/

  elasticsearch:
   # https://codingfundas.com/setting-up-elasticsearch-6-8-with-kibana-and-x-pack-security-enabled/index.html
   image: "docker.elastic.co/elasticsearch/elasticsearch:8.3.2"
   environment:
     - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
     - "discovery.type=single-node"
   ports:
     - "9200:9200"
   volumes:
     - elasticsearch_data:/usr/share/elasticsearch/data
     - ./elasticsearch.yml:/etc/elasticsearch/elasticsearch.yml
     - ./elastic-certificates.p12:/usr/share/elasticsearch/config/elastic-certificates.p12
  kibana:
   depends_on:
     - elasticsearch
   image: "docker.elastic.co/kibana/kibana:8.3.2"
   ports:
     - "5601:5601"
     - "8202:8200"
   volumes:
     - ./kibana.yml:/usr/share/kibana/config/kibana.yml

  filebeat:
    image: "docker.elastic.co/beats/filebeat:8.3.2"
#    user: root
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker:/var/lib/docker:ro
      - /var/run/docker.sock:/var/run/docker.sock

volumes: { "elasticsearch_data", "certs"}
